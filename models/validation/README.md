# Step 6: Model Validation Framework

## ðŸŽ¯ Overview

Comprehensive validation framework for AQI prediction models implementing multi-city validation, time-series forecasting evaluation, and API benchmarking as specified in Step 6 requirements.

## âœ… Status: Complete

- âœ… Multi-city validation (Delhi, Mumbai, Bangalore)
- âœ… Time-series forecasting (1-48 hour horizons)
- âœ… API benchmarking (IQAir, AQICN, research papers)
- âœ… Comprehensive reporting (JSON, Markdown, CSV, plots)
- âœ… Data preparation pipeline
- âœ… Integration tests

## ðŸš€ Quick Start

### 1. Test the Framework

```powershell
# Verify all components work
python tests/test_validation_framework.py
```

Expected output: All 4 tests pass âœ…

### 2. Prepare Real Data

```powershell
# Fetch from Render PostgreSQL database
python scripts/prepare_validation_data.py
```

This creates: `data/processed/validation_data_TIMESTAMP.csv`

### 3. Run Complete Validation

```powershell
# Get latest data file
$latest_data = Get-ChildItem data\processed\validation_data_*.csv | Sort-Object LastWriteTime -Descending | Select-Object -First 1

# Run validation
python models/run_step6_validation.py --data-path $latest_data.FullName
```

### 4. View Results

```powershell
# Get latest report
$latest_report = Get-ChildItem models\validation\reports\validation_report_*.md | Sort-Object LastWriteTime -Descending | Select-Object -First 1

# Open in VS Code
code $latest_report.FullName
```

## ðŸ“¦ What's Included

### Core Validation Modules

```
models/validation/
â”œâ”€â”€ multi_city_validator.py       # Geographic generalization (676 lines)
â”œâ”€â”€ forecasting_validator.py      # Temporal forecasting (553 lines)
â”œâ”€â”€ api_benchmark.py               # Commercial API comparison (490 lines)
â””â”€â”€ validation_report.py           # Report generation (571 lines)
```

### Orchestration & Tools

```
models/
â””â”€â”€ run_step6_validation.py        # Main orchestrator (475 lines)

scripts/
â””â”€â”€ prepare_validation_data.py     # Data pipeline (234 lines)

tests/
â””â”€â”€ test_validation_framework.py   # Integration tests (229 lines)
```

### Documentation

```
STEP6_VALIDATION_GUIDE.md          # Comprehensive user guide
STEP6_IMPLEMENTATION_SUMMARY.md    # Technical implementation details
models/validation/README.md         # This file
```

## ðŸ“Š Validation Components

### 1. Multi-City Validation

**Purpose**: Test geographic generalization

**Features**:
- Per-city hold-out validation
- Cross-city generalization tests
- Stratified metrics by AQI category
- Performance breakdown by pollution level

**Metrics**: RÂ², RMSE, MAE, MAPE, max error, median absolute error

### 2. Time-Series Forecasting

**Purpose**: Evaluate temporal prediction accuracy

**Features**:
- Walk-forward validation (no data leakage)
- Multi-horizon evaluation (1, 6, 12, 24, 48 hours)
- Directional accuracy tracking
- Skill score vs persistence baseline

**Metrics**: RÂ², RMSE, MAE, directional accuracy, bias, skill score

### 3. API Benchmarking

**Purpose**: Compare with industry standards

**Features**:
- IQAir API integration
- AQICN API integration
- Research benchmark database
- Improvement metrics

**Benchmarks**: Commercial APIs + 7 research papers (2023)

### 4. Comprehensive Reporting

**Purpose**: Generate actionable insights

**Outputs**:
- JSON report (complete results)
- Markdown report (human-readable)
- CSV summaries (3 tables)
- PNG plots (6-subplot visualization)

**Rankings**: Combined score (60% multi-city RÂ² + 40% forecasting RMSE)

## ðŸŽ“ Models Validated

1. **Linear Regression** - Baseline
2. **Random Forest** - Ensemble
3. **XGBoost** - Gradient boosting
4. **LSTM** - Neural network
5. **Stacked Ensemble** - Meta-learner

## ðŸ“ˆ Expected Performance

Based on 1,940+ records from 66 cities:

| Metric | Target | Typical Range |
|--------|--------|---------------|
| Multi-city RÂ² | > 0.80 | 0.75 - 0.90 |
| 1-hour RMSE | < 35 | 20 - 35 |
| 24-hour RMSE | < 50 | 35 - 50 |
| 48-hour RMSE | < 65 | 45 - 65 |

**Runtime**: ~10-15 minutes for complete validation

## ðŸ”§ Command Line Options

```bash
python models/run_step6_validation.py [OPTIONS]

Options:
  --data-path PATH           Path to processed data CSV (required)
  --cities CITY [CITY ...]   Cities to validate (default: Delhi Mumbai Bangalore)
  --horizons H [H ...]       Forecast horizons in hours (default: 1 6 12 24 48)
  --force-train              Force model retraining
  --iqair-key KEY            IQAir API key for live benchmarking
  --aqicn-key KEY            AQICN API key for live benchmarking
```

### Examples

```powershell
# Validate only Delhi with custom horizons
python models/run_step6_validation.py `
  --data-path data/processed/validation_data.csv `
  --cities Delhi `
  --horizons 1 12 24

# Force retrain all models
python models/run_step6_validation.py `
  --data-path data/processed/validation_data.csv `
  --force-train

# Include live API benchmarking
python models/run_step6_validation.py `
  --data-path data/processed/validation_data.csv `
  --iqair-key YOUR_IQAIR_KEY `
  --aqicn-key YOUR_AQICN_KEY
```

## ðŸ“‚ Output Structure

```
models/validation/reports/
â”œâ”€â”€ validation_report_20251106_143022.json    # Complete results
â”œâ”€â”€ validation_report_20251106_143022.md      # Human-readable
â”œâ”€â”€ multi_city_summary_20251106_143022.csv    # Per-city metrics
â”œâ”€â”€ forecasting_summary_20251106_143022.csv   # Per-horizon metrics
â”œâ”€â”€ model_rankings_20251106_143022.csv        # Overall rankings
â””â”€â”€ validation_plots_20251106_143022.png      # Visualizations
```

## ðŸ” Understanding Results

### Key Indicators

âœ… **Good Performance**:
- RÂ² > 0.80
- RMSE < 50
- Directional accuracy > 70%
- Skill score > 0

âš ï¸ **Warning Signs**:
- Large performance drop across cities (overfitting)
- Rapid RMSE increase with horizon (poor long-term forecasting)
- Negative skill score (worse than naive baseline)
- High bias (systematic error)

### Model Selection

The framework ranks models using a combined score:
```
Combined Score = 0.6 Ã— Multi-City RÂ² + 0.4 Ã— (1 - Normalized Forecasting RMSE)
```

Higher score = better overall performance

## ðŸ› ï¸ Troubleshooting

### No data available
```bash
python scripts/check_collection_status.py
python scripts/view_render_db_data.py
```

### Model training fails
- Ensure >500 records per city
- Check for missing values
- Verify column names
- Use `--force-train`

### Out of memory
- Reduce cities: `--cities Delhi`
- Reduce horizons: `--horizons 1 6 24`

### Import errors
```bash
pip install -r requirements.txt
pip install psycopg2-binary scikit-learn xgboost tensorflow
```

## ðŸ§ª Testing

Run integration tests to verify framework:

```bash
python tests/test_validation_framework.py
```

This tests all 4 components with synthetic data.

## ðŸ“š Documentation

- **STEP6_VALIDATION_GUIDE.md**: Comprehensive user guide with detailed methodology
- **STEP6_IMPLEMENTATION_SUMMARY.md**: Technical implementation details and architecture
- **Inline docs**: All classes and methods have docstrings

## ðŸ”„ Workflow Integration

### With Existing Pipeline

```python
# Use with your own models
from models.validation import MultiCityValidator

validator = MultiCityValidator(validation_cities=['Delhi', 'Mumbai'])
results = validator.validate_all_cities(your_models, your_data)
```

### Automated Validation

```bash
# Add to your CI/CD pipeline
python scripts/prepare_validation_data.py
python models/run_step6_validation.py --data-path data/processed/validation_data_*.csv
```

## ðŸ“Š Sample Output

```
================================================================================
STEP 6: COMPREHENSIVE MODEL VALIDATION
================================================================================

STEP 1: MULTI-CITY VALIDATION
--------------------------------------------------------------------------------
âœ“ Delhi: RÂ²=0.87, RMSE=32.5
âœ“ Mumbai: RÂ²=0.84, RMSE=36.2
âœ“ Bangalore: RÂ²=0.82, RMSE=38.1

STEP 2: TIME-SERIES FORECASTING VALIDATION
--------------------------------------------------------------------------------
1-hour:  RMSE=28.3, RÂ²=0.89, DA=78%
6-hour:  RMSE=34.1, RÂ²=0.85, DA=74%
24-hour: RMSE=42.7, RÂ²=0.79, DA=69%

STEP 3: API BENCHMARKING
--------------------------------------------------------------------------------
vs Kumar et al. (2023): 24.2% improvement
vs IQAir API: 12.5% improvement

GENERATING COMPREHENSIVE REPORT
--------------------------------------------------------------------------------
âœ“ JSON report saved
âœ“ Markdown report saved
âœ“ CSV summaries exported
âœ“ Plots generated

VALIDATION COMPLETE!
================================================================================
Best Overall Model: XGBoost
Combined Score: 0.8542
================================================================================
```

## ðŸŽ¯ Success Criteria (All Met âœ…)

- [x] Multi-city validation on Delhi, Mumbai, Bangalore
- [x] Time-series hold-out for 1-48 hour forecasting
- [x] Benchmark against IQAir and AQICN APIs
- [x] Compare with published research metrics
- [x] Comprehensive reporting with visualizations
- [x] Modular, reusable architecture
- [x] Full documentation
- [x] Integration tests

## ðŸ“ž Support

For issues or questions:

1. Check logs in `models/validation/validation_TIMESTAMP.log`
2. Review `STEP6_VALIDATION_GUIDE.md` for detailed guidance
3. Run integration tests: `python tests/test_validation_framework.py`
4. Verify database: `python scripts/test_db_connection.py`

## ðŸš€ Next Steps

1. **Run validation** on your real data
2. **Review results** in markdown report
3. **Select best model** based on rankings
4. **Deploy model** to production
5. **Monitor performance** continuously

---

**Framework Version**: 1.0  
**Last Updated**: November 2025  
**Status**: âœ… Production Ready
